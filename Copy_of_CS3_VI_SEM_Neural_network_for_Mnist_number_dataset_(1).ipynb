{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shobhit-joshi-8/ML-ANN/blob/main/Copy_of_CS3_VI_SEM_Neural_network_for_Mnist_number_dataset_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aK_1LHdwQpF9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mustafalw02/Machine-Learning-Lab-Work/blob/master/Neural_network_for_Mnist_number_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "zQvT7bhRzp4e"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-MNIST-dataset-in-Keras\" data-toc-modified-id=\"Loading-the-MNIST-dataset-in-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading the MNIST dataset in Keras</a></span></li><li><span><a href=\"#The-network-architecture\" data-toc-modified-id=\"The-network-architecture-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The network architecture</a></span></li><li><span><a href=\"#The-compilation-step\" data-toc-modified-id=\"The-compilation-step-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The compilation step</a></span></li><li><span><a href=\"#Preparing-the-image-data\" data-toc-modified-id=\"Preparing-the-image-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preparing the image data</a></span></li><li><span><a href=\"#Preparing-the-labels\" data-toc-modified-id=\"Preparing-the-labels-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preparing the labels</a></span></li><li><span><a href=\"#Training-and-Testing\" data-toc-modified-id=\"Training-and-Testing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training and Testing</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSee4zKUzp4i"
      },
      "source": [
        "# Loading the MNIST dataset in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a8IveFHzp4l"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPmnZ8xzp4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5795b1-84ca-4b93-c4dd-78b2f92eeb2f"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnZfS9HYzp4z"
      },
      "source": [
        "- The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFdoffSmzp41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd271e5-4da0-4cab-b057-33cf06815c3b"
      },
      "source": [
        "train_images.shape\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD65nC-vzp45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8002affc-ad0b-4230-9652-78b61523ed59"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX9LpWNazp4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e186e9c3-728a-4426-c752-ed28f5c8ad2a"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG0L5p4Dzp5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea3ebb5-2dea-4198-fe3d-e0c90f075f76"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MimOH_Xnzp5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a66a23-cb81-4d90-98d9-732f66f10f0f"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EHR0v0Bzp5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6918ba66-4c33-4bb0-9661-bb2f6aa7cde0"
      },
      "source": [
        "test_labels"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Tp6nDRzp5R"
      },
      "source": [
        "Let's build the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxbJXg2Czp5T"
      },
      "source": [
        "# The network architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGCxNrDdzp5U"
      },
      "source": [
        "- The core building block of neural networks is the **layer**, a data-processing module that you can think of as a filter for data.\n",
        "    - Some data goes in, and it comes out in a more useful form.\n",
        "    - Layers extract **representations** (hopefully, meaningful for the data problem at hand) out of the data fed into them.\n",
        "    \n",
        "- Most of deep learning consists of chaining together simple layers that will implement a form of progressive **data distillation**.\n",
        "- A deep learning model is like a sieve for data-processing, made of a succession of increasingly refined data filters--**the layers**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyUqGjPTzp5V"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEVk0S9_zp5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d3469a-c0e3-4ba9-b3b3-c1ae5530ac3a"
      },
      "source": [
        "network = models.Sequential()\n",
        "# Dense(32) is a fully-connected layer with 32 hidden units.\n",
        "# in the first layer, you must specify the expected input data shape :\n",
        "# here, 28 X 28=784 -dimensional vectors.\n",
        "network.add(layers.Dense(32, activation='sigmoid', input_shape=(28 * 28, )))\n",
        "network.add(layers.Dense(8, activation='sigmoid'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                90        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,474\n",
            "Trainable params: 25,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJSFxZe_e0vC",
        "outputId": "fe8a3ca6-e429-42a7-eeae-fa4938777c29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af2c2tvKzp5f"
      },
      "source": [
        "- Our network consists of a sequence of two *Dense* layers, which are densely connected (also called *fully connected*) neural layers.\n",
        "- The second (and last) layer is a **10-way** *softmax* layer, which means it will return an array of **10** probability scores. Each score will be the probability that the current digit image belongs to one of our 10 digit classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHbqJ-rWzp5g"
      },
      "source": [
        "# The compilation step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w0ne5wYzp5h"
      },
      "source": [
        "- To make the network ready for training, we need to pick three more things, as part of the **compilation** step:\n",
        " - **A loss function**-- How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
        " - **An optimizer**--The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
        " - **Metrics to monitor during training and testing**--Here, we will only care about accuracy (the fraction of the images that were correctly classified)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvSO-q9Ozp5i"
      },
      "source": [
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLHJqTLXzp5o"
      },
      "source": [
        "# Preparing the image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajWKVl1-zp5q"
      },
      "source": [
        "Before training, we will preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the $[0-1]$ interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vMdz75Wzp5s"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4icW7vDgzp5w"
      },
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SHD8Vvhzp5z"
      },
      "source": [
        "# Preparing the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA1YmuF1zp51"
      },
      "source": [
        "We also need to categorically encode the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh42ABtgzp58"
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCqlapJzp6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa7e644-076f-405b-dfd6-b7992cefa94f"
      },
      "source": [
        "train_labels = to_categorical(train_labels)\n",
        "train_labels"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWXDQKNBzp6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee5e0c6-d504-4eb4-f176-3f09b0b61624"
      },
      "source": [
        "test_labels = to_categorical(test_labels)\n",
        "test_labels"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csJ7yQVxzp6I"
      },
      "source": [
        "# Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-KLV-VIzp6K"
      },
      "source": [
        "We are now ready to train the network, which in Keras is done via a call to the network's fit method--we fit the model to its training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGWa7zXYzp6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c968b46f-4239-4cba-eb7b-ff822e99fffc"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=250, batch_size=512)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9855 - accuracy: 0.4737\n",
            "Epoch 2/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9661 - accuracy: 0.4760\n",
            "Epoch 3/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9463 - accuracy: 0.4777\n",
            "Epoch 4/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9261 - accuracy: 0.4798\n",
            "Epoch 5/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.9055 - accuracy: 0.4833\n",
            "Epoch 6/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8845 - accuracy: 0.4844\n",
            "Epoch 7/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8634 - accuracy: 0.4861\n",
            "Epoch 8/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8421 - accuracy: 0.4888\n",
            "Epoch 9/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8206 - accuracy: 0.4913\n",
            "Epoch 10/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7991 - accuracy: 0.4936\n",
            "Epoch 11/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.7775 - accuracy: 0.4954\n",
            "Epoch 12/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.7561 - accuracy: 0.4986\n",
            "Epoch 13/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.7347 - accuracy: 0.5014\n",
            "Epoch 14/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.7134 - accuracy: 0.5031\n",
            "Epoch 15/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.6924 - accuracy: 0.5067\n",
            "Epoch 16/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.6716 - accuracy: 0.5096\n",
            "Epoch 17/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6510 - accuracy: 0.5127\n",
            "Epoch 18/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6307 - accuracy: 0.5157\n",
            "Epoch 19/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6107 - accuracy: 0.5198\n",
            "Epoch 20/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5911 - accuracy: 0.5225\n",
            "Epoch 21/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5718 - accuracy: 0.5260\n",
            "Epoch 22/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5530 - accuracy: 0.5290\n",
            "Epoch 23/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5345 - accuracy: 0.5320\n",
            "Epoch 24/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5165 - accuracy: 0.5360\n",
            "Epoch 25/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4988 - accuracy: 0.5388\n",
            "Epoch 26/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4816 - accuracy: 0.5431\n",
            "Epoch 27/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4649 - accuracy: 0.5469\n",
            "Epoch 28/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4485 - accuracy: 0.5495\n",
            "Epoch 29/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4326 - accuracy: 0.5539\n",
            "Epoch 30/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4171 - accuracy: 0.5579\n",
            "Epoch 31/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4021 - accuracy: 0.5616\n",
            "Epoch 32/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3874 - accuracy: 0.5644\n",
            "Epoch 33/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3732 - accuracy: 0.5686\n",
            "Epoch 34/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3593 - accuracy: 0.5718\n",
            "Epoch 35/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3459 - accuracy: 0.5757\n",
            "Epoch 36/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3328 - accuracy: 0.5792\n",
            "Epoch 37/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3201 - accuracy: 0.5832\n",
            "Epoch 38/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3077 - accuracy: 0.5864\n",
            "Epoch 39/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2957 - accuracy: 0.5895\n",
            "Epoch 40/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2840 - accuracy: 0.5934\n",
            "Epoch 41/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2726 - accuracy: 0.5971\n",
            "Epoch 42/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2616 - accuracy: 0.6000\n",
            "Epoch 43/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2508 - accuracy: 0.6034\n",
            "Epoch 44/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2403 - accuracy: 0.6076\n",
            "Epoch 45/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.2301 - accuracy: 0.6112\n",
            "Epoch 46/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2201 - accuracy: 0.6155\n",
            "Epoch 47/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2103 - accuracy: 0.6185\n",
            "Epoch 48/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2009 - accuracy: 0.6222\n",
            "Epoch 49/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1916 - accuracy: 0.6258\n",
            "Epoch 50/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1825 - accuracy: 0.6290\n",
            "Epoch 51/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1737 - accuracy: 0.6331\n",
            "Epoch 52/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1650 - accuracy: 0.6360\n",
            "Epoch 53/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1565 - accuracy: 0.6398\n",
            "Epoch 54/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1482 - accuracy: 0.6440\n",
            "Epoch 55/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1401 - accuracy: 0.6475\n",
            "Epoch 56/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1322 - accuracy: 0.6511\n",
            "Epoch 57/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1243 - accuracy: 0.6552\n",
            "Epoch 58/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1167 - accuracy: 0.6585\n",
            "Epoch 59/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1091 - accuracy: 0.6625\n",
            "Epoch 60/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1017 - accuracy: 0.6666\n",
            "Epoch 61/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0944 - accuracy: 0.6693\n",
            "Epoch 62/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0873 - accuracy: 0.6740\n",
            "Epoch 63/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0803 - accuracy: 0.6772\n",
            "Epoch 64/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0733 - accuracy: 0.6805\n",
            "Epoch 65/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0665 - accuracy: 0.6834\n",
            "Epoch 66/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0597 - accuracy: 0.6869\n",
            "Epoch 67/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.0531 - accuracy: 0.6892\n",
            "Epoch 68/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.0465 - accuracy: 0.6920\n",
            "Epoch 69/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.0401 - accuracy: 0.6952\n",
            "Epoch 70/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.0337 - accuracy: 0.6980\n",
            "Epoch 71/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.0274 - accuracy: 0.7007\n",
            "Epoch 72/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.0212 - accuracy: 0.7033\n",
            "Epoch 73/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.0150 - accuracy: 0.7064\n",
            "Epoch 74/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.7092\n",
            "Epoch 75/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0029 - accuracy: 0.7115\n",
            "Epoch 76/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9969 - accuracy: 0.7137\n",
            "Epoch 77/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9910 - accuracy: 0.7161\n",
            "Epoch 78/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9851 - accuracy: 0.7187\n",
            "Epoch 79/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9793 - accuracy: 0.7210\n",
            "Epoch 80/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9736 - accuracy: 0.7236\n",
            "Epoch 81/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9679 - accuracy: 0.7255\n",
            "Epoch 82/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9623 - accuracy: 0.7279\n",
            "Epoch 83/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9567 - accuracy: 0.7303\n",
            "Epoch 84/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9512 - accuracy: 0.7328\n",
            "Epoch 85/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9456 - accuracy: 0.7347\n",
            "Epoch 86/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9402 - accuracy: 0.7376\n",
            "Epoch 87/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.7402\n",
            "Epoch 88/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9294 - accuracy: 0.7420\n",
            "Epoch 89/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9240 - accuracy: 0.7442\n",
            "Epoch 90/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.9187 - accuracy: 0.7467\n",
            "Epoch 91/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.9134 - accuracy: 0.7483\n",
            "Epoch 92/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.9082 - accuracy: 0.7508\n",
            "Epoch 93/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.9030 - accuracy: 0.7538\n",
            "Epoch 94/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.8978 - accuracy: 0.7556\n",
            "Epoch 95/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8926 - accuracy: 0.7579\n",
            "Epoch 96/500\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.8875 - accuracy: 0.7597\n",
            "Epoch 97/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8823 - accuracy: 0.7624\n",
            "Epoch 98/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8772 - accuracy: 0.7648\n",
            "Epoch 99/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.8722 - accuracy: 0.7669\n",
            "Epoch 100/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.8671 - accuracy: 0.7698\n",
            "Epoch 101/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.8620 - accuracy: 0.7722\n",
            "Epoch 102/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.8570 - accuracy: 0.7743\n",
            "Epoch 103/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8520 - accuracy: 0.7767\n",
            "Epoch 104/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8470 - accuracy: 0.7794\n",
            "Epoch 105/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8420 - accuracy: 0.7816\n",
            "Epoch 106/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8370 - accuracy: 0.7837\n",
            "Epoch 107/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8320 - accuracy: 0.7859\n",
            "Epoch 108/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8270 - accuracy: 0.7877\n",
            "Epoch 109/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8221 - accuracy: 0.7899\n",
            "Epoch 110/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8171 - accuracy: 0.7920\n",
            "Epoch 111/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8122 - accuracy: 0.7944\n",
            "Epoch 112/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8072 - accuracy: 0.7965\n",
            "Epoch 113/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.7984\n",
            "Epoch 114/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7973 - accuracy: 0.8002\n",
            "Epoch 115/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.8020\n",
            "Epoch 116/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7875 - accuracy: 0.8034\n",
            "Epoch 117/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.8050\n",
            "Epoch 118/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7777 - accuracy: 0.8071\n",
            "Epoch 119/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7728 - accuracy: 0.8088\n",
            "Epoch 120/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7680 - accuracy: 0.8106\n",
            "Epoch 121/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.8126\n",
            "Epoch 122/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7583 - accuracy: 0.8140\n",
            "Epoch 123/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7534 - accuracy: 0.8157\n",
            "Epoch 124/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7486 - accuracy: 0.8170\n",
            "Epoch 125/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7438 - accuracy: 0.8187\n",
            "Epoch 126/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7390 - accuracy: 0.8200\n",
            "Epoch 127/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7343 - accuracy: 0.8215\n",
            "Epoch 128/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7296 - accuracy: 0.8229\n",
            "Epoch 129/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7248 - accuracy: 0.8242\n",
            "Epoch 130/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.7202 - accuracy: 0.8256\n",
            "Epoch 131/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7155 - accuracy: 0.8269\n",
            "Epoch 132/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.8280\n",
            "Epoch 133/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.8292\n",
            "Epoch 134/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.8305\n",
            "Epoch 135/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.8316\n",
            "Epoch 136/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.8326\n",
            "Epoch 137/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.8335\n",
            "Epoch 138/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.8347\n",
            "Epoch 139/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.8359\n",
            "Epoch 140/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.8371\n",
            "Epoch 141/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.8381\n",
            "Epoch 142/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.8392\n",
            "Epoch 143/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.8404\n",
            "Epoch 144/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.8414\n",
            "Epoch 145/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.8424\n",
            "Epoch 146/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.8437\n",
            "Epoch 147/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.8449\n",
            "Epoch 148/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.8457\n",
            "Epoch 149/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.8470\n",
            "Epoch 150/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.8478\n",
            "Epoch 151/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.8488\n",
            "Epoch 152/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.8496\n",
            "Epoch 153/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.8506\n",
            "Epoch 154/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.6184 - accuracy: 0.8511\n",
            "Epoch 155/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.8522\n",
            "Epoch 156/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.6111 - accuracy: 0.8530\n",
            "Epoch 157/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.6074 - accuracy: 0.8535\n",
            "Epoch 158/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.6039 - accuracy: 0.8543\n",
            "Epoch 159/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.6003 - accuracy: 0.8553\n",
            "Epoch 160/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.8561\n",
            "Epoch 161/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.8567\n",
            "Epoch 162/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.8572\n",
            "Epoch 163/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.8581\n",
            "Epoch 164/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.8586\n",
            "Epoch 165/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.8592\n",
            "Epoch 166/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8598\n",
            "Epoch 167/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.8607\n",
            "Epoch 168/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.8615\n",
            "Epoch 169/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.8621\n",
            "Epoch 170/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.8624\n",
            "Epoch 171/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.8633\n",
            "Epoch 172/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.8638\n",
            "Epoch 173/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.8641\n",
            "Epoch 174/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.8651\n",
            "Epoch 175/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.8655\n",
            "Epoch 176/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.8658\n",
            "Epoch 177/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.8663\n",
            "Epoch 178/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.8670\n",
            "Epoch 179/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.8677\n",
            "Epoch 180/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.8681\n",
            "Epoch 181/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.5333 - accuracy: 0.8689\n",
            "Epoch 182/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.5307 - accuracy: 0.8696\n",
            "Epoch 183/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.8700\n",
            "Epoch 184/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.8707\n",
            "Epoch 185/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.8709\n",
            "Epoch 186/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.8714\n",
            "Epoch 187/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.5182 - accuracy: 0.8718\n",
            "Epoch 188/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.5158 - accuracy: 0.8722\n",
            "Epoch 189/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.8729\n",
            "Epoch 190/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.8733\n",
            "Epoch 191/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.8740\n",
            "Epoch 192/500\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.5065 - accuracy: 0.8744\n",
            "Epoch 193/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8749\n",
            "Epoch 194/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.5020 - accuracy: 0.8751\n",
            "Epoch 195/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.8755\n",
            "Epoch 196/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.8760\n",
            "Epoch 197/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.8762\n",
            "Epoch 198/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.8769\n",
            "Epoch 199/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.8770\n",
            "Epoch 200/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.8776\n",
            "Epoch 201/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.8779\n",
            "Epoch 202/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8783\n",
            "Epoch 203/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.8786\n",
            "Epoch 204/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8789\n",
            "Epoch 205/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.8793\n",
            "Epoch 206/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8796\n",
            "Epoch 207/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8800\n",
            "Epoch 208/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.4738 - accuracy: 0.8805\n",
            "Epoch 209/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4720 - accuracy: 0.8809\n",
            "Epoch 210/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.8813\n",
            "Epoch 211/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.8819\n",
            "Epoch 212/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.8819\n",
            "Epoch 213/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.8825\n",
            "Epoch 214/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4631 - accuracy: 0.8830\n",
            "Epoch 215/500\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.4614 - accuracy: 0.8836\n",
            "Epoch 216/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.4597 - accuracy: 0.8838\n",
            "Epoch 217/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4581 - accuracy: 0.8841\n",
            "Epoch 218/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4564 - accuracy: 0.8844\n",
            "Epoch 219/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4548 - accuracy: 0.8846\n",
            "Epoch 220/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8852\n",
            "Epoch 221/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4516 - accuracy: 0.8855\n",
            "Epoch 222/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8860\n",
            "Epoch 223/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8863\n",
            "Epoch 224/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.8867\n",
            "Epoch 225/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8868\n",
            "Epoch 226/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8871\n",
            "Epoch 227/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8876\n",
            "Epoch 228/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8878\n",
            "Epoch 229/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8882\n",
            "Epoch 230/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8885\n",
            "Epoch 231/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8888\n",
            "Epoch 232/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8891\n",
            "Epoch 233/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8892\n",
            "Epoch 234/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8895\n",
            "Epoch 235/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.8897\n",
            "Epoch 236/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4298 - accuracy: 0.8899\n",
            "Epoch 237/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.8903\n",
            "Epoch 238/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4271 - accuracy: 0.8905\n",
            "Epoch 239/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8909\n",
            "Epoch 240/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4245 - accuracy: 0.8912\n",
            "Epoch 241/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.8915\n",
            "Epoch 242/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8917\n",
            "Epoch 243/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8919\n",
            "Epoch 244/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8922\n",
            "Epoch 245/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8924\n",
            "Epoch 246/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8925\n",
            "Epoch 247/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8929\n",
            "Epoch 248/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8932\n",
            "Epoch 249/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8934\n",
            "Epoch 250/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8937\n",
            "Epoch 251/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8939\n",
            "Epoch 252/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8943\n",
            "Epoch 253/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8944\n",
            "Epoch 254/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8948\n",
            "Epoch 255/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8948\n",
            "Epoch 256/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8952\n",
            "Epoch 257/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8952\n",
            "Epoch 258/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8954\n",
            "Epoch 259/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8958\n",
            "Epoch 260/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8960\n",
            "Epoch 261/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8962\n",
            "Epoch 262/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8964\n",
            "Epoch 263/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8967\n",
            "Epoch 264/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3970 - accuracy: 0.8969\n",
            "Epoch 265/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3960 - accuracy: 0.8971\n",
            "Epoch 266/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.8974\n",
            "Epoch 267/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3940 - accuracy: 0.8976\n",
            "Epoch 268/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3930 - accuracy: 0.8978\n",
            "Epoch 269/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3920 - accuracy: 0.8979\n",
            "Epoch 270/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3911 - accuracy: 0.8981\n",
            "Epoch 271/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8983\n",
            "Epoch 272/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8983\n",
            "Epoch 273/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8986\n",
            "Epoch 274/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8989\n",
            "Epoch 275/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8993\n",
            "Epoch 276/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8993\n",
            "Epoch 277/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8997\n",
            "Epoch 278/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8997\n",
            "Epoch 279/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.9000\n",
            "Epoch 280/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.9001\n",
            "Epoch 281/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.9004\n",
            "Epoch 282/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.9006\n",
            "Epoch 283/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.9009\n",
            "Epoch 284/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.9009\n",
            "Epoch 285/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.9013\n",
            "Epoch 286/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.9015\n",
            "Epoch 287/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.9018\n",
            "Epoch 288/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.9021\n",
            "Epoch 289/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.9022\n",
            "Epoch 290/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.9023\n",
            "Epoch 291/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.9025\n",
            "Epoch 292/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3715 - accuracy: 0.9028\n",
            "Epoch 293/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3707 - accuracy: 0.9031\n",
            "Epoch 294/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3699 - accuracy: 0.9034\n",
            "Epoch 295/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.9034\n",
            "Epoch 296/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3683 - accuracy: 0.9037\n",
            "Epoch 297/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.9039\n",
            "Epoch 298/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.9041\n",
            "Epoch 299/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.9042\n",
            "Epoch 300/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.9045\n",
            "Epoch 301/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.9046\n",
            "Epoch 302/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.9048\n",
            "Epoch 303/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3628 - accuracy: 0.9050\n",
            "Epoch 304/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.9049\n",
            "Epoch 305/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.9053\n",
            "Epoch 306/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.9053\n",
            "Epoch 307/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.9055\n",
            "Epoch 308/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.9056\n",
            "Epoch 309/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.9059\n",
            "Epoch 310/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.9060\n",
            "Epoch 311/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.9061\n",
            "Epoch 312/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.9064\n",
            "Epoch 313/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.9065\n",
            "Epoch 314/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.9067\n",
            "Epoch 315/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.9068\n",
            "Epoch 316/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.9070\n",
            "Epoch 317/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.9072\n",
            "Epoch 318/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.9075\n",
            "Epoch 319/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.9076\n",
            "Epoch 320/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3507 - accuracy: 0.9078\n",
            "Epoch 321/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3500 - accuracy: 0.9080\n",
            "Epoch 322/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3493 - accuracy: 0.9081\n",
            "Epoch 323/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3487 - accuracy: 0.9082\n",
            "Epoch 324/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.9083\n",
            "Epoch 325/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3474 - accuracy: 0.9085\n",
            "Epoch 326/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.9086\n",
            "Epoch 327/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.9088\n",
            "Epoch 328/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.9088\n",
            "Epoch 329/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.9092\n",
            "Epoch 330/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.9091\n",
            "Epoch 331/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.9094\n",
            "Epoch 332/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.9096\n",
            "Epoch 333/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.9097\n",
            "Epoch 334/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.9100\n",
            "Epoch 335/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.9099\n",
            "Epoch 336/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.9102\n",
            "Epoch 337/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.9102\n",
            "Epoch 338/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.9105\n",
            "Epoch 339/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.9104\n",
            "Epoch 340/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.9107\n",
            "Epoch 341/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.9107\n",
            "Epoch 342/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.9111\n",
            "Epoch 343/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3361 - accuracy: 0.9111\n",
            "Epoch 344/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3355 - accuracy: 0.9111\n",
            "Epoch 345/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3349 - accuracy: 0.9113\n",
            "Epoch 346/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.9114\n",
            "Epoch 347/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3338 - accuracy: 0.9116\n",
            "Epoch 348/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3332 - accuracy: 0.9118\n",
            "Epoch 349/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3326 - accuracy: 0.9119\n",
            "Epoch 350/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.3320 - accuracy: 0.9120\n",
            "Epoch 351/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.9122\n",
            "Epoch 352/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3309 - accuracy: 0.9123\n",
            "Epoch 353/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.9124\n",
            "Epoch 354/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.9125\n",
            "Epoch 355/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.9128\n",
            "Epoch 356/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.9129\n",
            "Epoch 357/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.9129\n",
            "Epoch 358/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.9130\n",
            "Epoch 359/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.9132\n",
            "Epoch 360/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.9131\n",
            "Epoch 361/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.9135\n",
            "Epoch 362/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.9137\n",
            "Epoch 363/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.9137\n",
            "Epoch 364/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.9136\n",
            "Epoch 365/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.9139\n",
            "Epoch 366/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.9142\n",
            "Epoch 367/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.9142\n",
            "Epoch 368/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.9144\n",
            "Epoch 369/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.9144\n",
            "Epoch 370/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.9147\n",
            "Epoch 371/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.9149\n",
            "Epoch 372/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.9148\n",
            "Epoch 373/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.9151\n",
            "Epoch 374/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.9152\n",
            "Epoch 375/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.9153\n",
            "Epoch 376/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.9154\n",
            "Epoch 377/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3175 - accuracy: 0.9155\n",
            "Epoch 378/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3170 - accuracy: 0.9156\n",
            "Epoch 379/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3165 - accuracy: 0.9157\n",
            "Epoch 380/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3160 - accuracy: 0.9158\n",
            "Epoch 381/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3155 - accuracy: 0.9159\n",
            "Epoch 382/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3149 - accuracy: 0.9162\n",
            "Epoch 383/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3145 - accuracy: 0.9163\n",
            "Epoch 384/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.9162\n",
            "Epoch 385/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.9166\n",
            "Epoch 386/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.9165\n",
            "Epoch 387/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.9166\n",
            "Epoch 388/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.9168\n",
            "Epoch 389/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.9168\n",
            "Epoch 390/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.9170\n",
            "Epoch 391/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.9171\n",
            "Epoch 392/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3101 - accuracy: 0.9172\n",
            "Epoch 393/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3096 - accuracy: 0.9174\n",
            "Epoch 394/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.3091 - accuracy: 0.9174\n",
            "Epoch 395/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.9175\n",
            "Epoch 396/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.9177\n",
            "Epoch 397/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.9178\n",
            "Epoch 398/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.9179\n",
            "Epoch 399/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.9181\n",
            "Epoch 400/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.9183\n",
            "Epoch 401/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.9182\n",
            "Epoch 402/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.9183\n",
            "Epoch 403/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.9185\n",
            "Epoch 404/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3045 - accuracy: 0.9187\n",
            "Epoch 405/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3040 - accuracy: 0.9186\n",
            "Epoch 406/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3036 - accuracy: 0.9187\n",
            "Epoch 407/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.9188\n",
            "Epoch 408/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3027 - accuracy: 0.9189\n",
            "Epoch 409/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3022 - accuracy: 0.9192\n",
            "Epoch 410/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3018 - accuracy: 0.9192\n",
            "Epoch 411/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.3013 - accuracy: 0.9193\n",
            "Epoch 412/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.9194\n",
            "Epoch 413/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.9197\n",
            "Epoch 414/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9199\n",
            "Epoch 415/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.9200\n",
            "Epoch 416/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.9202\n",
            "Epoch 417/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.9201\n",
            "Epoch 418/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.9204\n",
            "Epoch 419/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.9205\n",
            "Epoch 420/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.9207\n",
            "Epoch 421/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.9206\n",
            "Epoch 422/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.9207\n",
            "Epoch 423/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.9208\n",
            "Epoch 424/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.9211\n",
            "Epoch 425/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.9212\n",
            "Epoch 426/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.9214\n",
            "Epoch 427/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.9213\n",
            "Epoch 428/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.9214\n",
            "Epoch 429/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.9216\n",
            "Epoch 430/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.9218\n",
            "Epoch 431/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9219\n",
            "Epoch 432/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2923 - accuracy: 0.9219\n",
            "Epoch 433/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2919 - accuracy: 0.9220\n",
            "Epoch 434/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2915 - accuracy: 0.9221\n",
            "Epoch 435/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2911 - accuracy: 0.9223\n",
            "Epoch 436/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.9224\n",
            "Epoch 437/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2902 - accuracy: 0.9224\n",
            "Epoch 438/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2898 - accuracy: 0.9225\n",
            "Epoch 439/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2894 - accuracy: 0.9226\n",
            "Epoch 440/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2890 - accuracy: 0.9228\n",
            "Epoch 441/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9229\n",
            "Epoch 442/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.9232\n",
            "Epoch 443/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.9231\n",
            "Epoch 444/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.9231\n",
            "Epoch 445/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.9233\n",
            "Epoch 446/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2866 - accuracy: 0.9234\n",
            "Epoch 447/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.9235\n",
            "Epoch 448/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2858 - accuracy: 0.9237\n",
            "Epoch 449/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.9236\n",
            "Epoch 450/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.9238\n",
            "Epoch 451/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.9240\n",
            "Epoch 452/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.9238\n",
            "Epoch 453/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2838 - accuracy: 0.9240\n",
            "Epoch 454/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.9241\n",
            "Epoch 455/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.9242\n",
            "Epoch 456/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2827 - accuracy: 0.9244\n",
            "Epoch 457/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2823 - accuracy: 0.9245\n",
            "Epoch 458/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2819 - accuracy: 0.9246\n",
            "Epoch 459/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2815 - accuracy: 0.9247\n",
            "Epoch 460/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2811 - accuracy: 0.9248\n",
            "Epoch 461/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2808 - accuracy: 0.9248\n",
            "Epoch 462/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2804 - accuracy: 0.9250\n",
            "Epoch 463/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2800 - accuracy: 0.9249\n",
            "Epoch 464/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2796 - accuracy: 0.9251\n",
            "Epoch 465/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2792 - accuracy: 0.9252\n",
            "Epoch 466/500\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.2789 - accuracy: 0.9252\n",
            "Epoch 467/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2785 - accuracy: 0.9254\n",
            "Epoch 468/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2781 - accuracy: 0.9253\n",
            "Epoch 469/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2777 - accuracy: 0.9255\n",
            "Epoch 470/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2774 - accuracy: 0.9256\n",
            "Epoch 471/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2770 - accuracy: 0.9255\n",
            "Epoch 472/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2766 - accuracy: 0.9258\n",
            "Epoch 473/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.9258\n",
            "Epoch 474/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2759 - accuracy: 0.9260\n",
            "Epoch 475/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.9261\n",
            "Epoch 476/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.9263\n",
            "Epoch 477/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.9263\n",
            "Epoch 478/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.9264\n",
            "Epoch 479/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2741 - accuracy: 0.9265\n",
            "Epoch 480/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.9267\n",
            "Epoch 481/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2733 - accuracy: 0.9266\n",
            "Epoch 482/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.9268\n",
            "Epoch 483/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2726 - accuracy: 0.9270\n",
            "Epoch 484/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.9268\n",
            "Epoch 485/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9271\n",
            "Epoch 486/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.9271\n",
            "Epoch 487/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.9271\n",
            "Epoch 488/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2708 - accuracy: 0.9273\n",
            "Epoch 489/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2705 - accuracy: 0.9274\n",
            "Epoch 490/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2701 - accuracy: 0.9275\n",
            "Epoch 491/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2698 - accuracy: 0.9276\n",
            "Epoch 492/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2694 - accuracy: 0.9278\n",
            "Epoch 493/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.9278\n",
            "Epoch 494/500\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.2687 - accuracy: 0.9277\n",
            "Epoch 495/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2684 - accuracy: 0.9280\n",
            "Epoch 496/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2680 - accuracy: 0.9279\n",
            "Epoch 497/500\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 0.2677 - accuracy: 0.9281\n",
            "Epoch 498/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9281\n",
            "Epoch 499/500\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.9283\n",
            "Epoch 500/500\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38c95fda00>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heVasO26zp6V"
      },
      "source": [
        "- Two quantities are displayed during training:\n",
        "    - The loss of the network over the training data\n",
        "    - The accuracy of the network over the training data\n",
        "    \n",
        "- We quickly reach an accuracy of **$0.9886 (98.86\\%)$** on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eDaNGAYzp6X"
      },
      "source": [
        "- Now let's check that the model performs well on the test set, too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-UhmyTWzp6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebdbb10b-d4f2-45a3-dcaa-c07f36189107"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2703 - accuracy: 0.9257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omz-cZXLzp6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4694fce-970a-4f2c-bde3-b5e376fb441e"
      },
      "source": [
        "print('Test Accuracy: {:.5f} '.format(test_acc))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.92570 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbIp64KFzp6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943d0c1a-d66a-450d-e663-4396064bd4a0"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9257000088691711"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi5jDr-0zp6k"
      },
      "source": [
        "- The test-set accuracy turns out to be $97.780\\%$--that is quite a bit lower than the training set accuracy. This gap between training and test accuracy is an example of **overfitting**:the fact that the ML models tend to perform worse on new data than on their training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOu1IQW6zp6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "b300c0d4-c056-45a9-e998-b7412e03d50c"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(network, to_file='model.png')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAN8AAAFgCAYAAAA7Eqw4AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3de1BU5/0G8Ocsl70gC2pAYrgE0GhESWsbYxBTUrWNsXGqi4JKjKZ2NDZNc9GQisPPSWuNQSVTI01R6/QyQxYw9dbGjNWGtlOSMS1qIkGjDihBBA1llSWwwPf3h8O2BFGu++6B5zOzM3rOe97zPe+ehz17dvccTUQERORpBQbVFRANVQwfkSIMH5EiDB+RIr5fnVBcXIxt27apqIVo0CooKOg0rdMr36VLl1BYWOiRgqj/FBYWorKyUnUZ9BWVlZVd5qnTK1+7WyWVvJemaXjhhRewcOFC1aXQ/8jPz0dKSsot5/E9H5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgMSvhUrViAwMBCapuHEiRMDsYoB8ec//xlBQUE4ePCg6lIG1AcffID7778fBoMBmqZh1KhR+PnPf666LOzduxcxMTHQNA2apiEsLAxpaWmqyxowXf6ery927dqFmTNnYtGiRQPR/YAZKldRnDp1Kj799FM89thjeO+993DmzBkEBwerLgs2mw02mw1jxozB1atXUV1drbqkAcXDzv8xZ84c1NfX44knnlCy/sbGRiQkJChZtwpDbXu/asDCp2naQHU9aO3evRs1NTWqy/CYoba9X9Uv4RMRZGVlYdy4cTAajQgKCsLatWs7tGltbUVmZiYiIyNhNpsRHx8Pu90OAMjJyUFAQAAsFgv279+P2bNnw2q1Ijw8HHl5ee4+ioqKMGXKFFgsFlitVkyaNAkOh+OO/XfHP/7xD0RGRkLTNLz55pvdruuXv/wlTCYTQkNDsWrVKtx9990wmUxISEjAhx9+CAB47rnn4O/vj7CwMPf6fvSjHyEgIACapuHq1at4/vnn8dJLL+H8+fPQNA1jxozpxTPRN3rb3r///e+YMGECgoKCYDKZMGnSJLz33nsAbp53aH/vGBsbi5KSEgDA8uXLYbFYEBQUhAMHDtx2v3n99ddhsVgQGBiImpoavPTSS7jnnntw5syZPo2zm3yF3W6XW0y+rYyMDNE0TbZu3Sp1dXXidDplx44dAkBKSkpERGTNmjViNBqlsLBQ6urqZN26dWIwGOT48ePuPgDI0aNHpb6+XmpqamT69OkSEBAgzc3NcuPGDbFarbJ582ZpbGyU6upqmT9/vtTW1nar/+64dOmSAJDt27d32Lbb1SUisnLlSgkICJDS0lL58ssv5fTp0/Lggw9KYGCgXLx4UURElixZIqNGjeqwvqysLAHg3gabzSaxsbE9Gvt2AMRut/dome9+97sCQOrq6rxqe2NjYyUoKOiO9RcUFMiGDRvkiy++kGvXrsnUqVNl5MiR7vk2m018fHzk888/77Dc4sWL5cCBAyLS/f3yJz/5iWzfvl3mz58vn3766R1ra3ebPOX3+ZWvsbER2dnZmDlzJl588UUEBwfDbDZjxIgR7jZffvklcnJyMG/ePNhsNgQHB2P9+vXw8/PDnj17OvSXkJAAq9WKkJAQpKamoqGhARcvXkR5eTkcDgfi4uJgMpkwatQo7N27F3fddVeP+u+trupq5+vri/vvvx9GoxETJkxATk4Orl+/3m/r9zQ9bG9ycjL+7//+D8OHD8eIESMwd+5cXLt2DbW1tQCAZ555Bq2trR1qcjgcOH78OB5//PEe7TevvfYann32Wezduxfjx4/vl/r7HL5z587B6XRixowZXbY5c+YMnE4nJk6c6J5mNpsRFhaGsrKyLpfz9/cHALhcLsTExCA0NBRpaWnYsGEDysvL+9x/b/1vXV355je/CYvFMiDr9zS9bK+fnx+Am29BAODb3/427rvvPvzmN79xn8l+++23kZqaCh8fH4/vN1/V5/C1XysyJCSkyzYNDQ0AgPXr17uPwzVNQ0VFBZxOZ7fWYzabcezYMSQmJmLjxo2IiYlBamoqGhsb+6X/gWA0Gt1/hYcCT2/vn/70JyQlJSEkJARGoxEvv/xyh/mapmHVqlW4cOECjh49CgD43e9+hx/84AcA+me/7Is+h89kMgEAmpqaumzTHszs7GyISIdHcXFxt9cVFxeHgwcPoqqqCunp6bDb7diyZUu/9d+fXC4X/vOf/yA8PFzJ+j3NU9v7t7/9DdnZ2bh48SLmzZuHsLAwfPjhh6ivr8fmzZs7tV+2bBlMJhN27dqFM2fOwGq1IioqCkD/7Ze91efwTZw4EQaDAUVFRV22iYiIgMlk6tO3XaqqqlBaWgrg5qBt2rQJkydPRmlpab/039/ef/99iAimTp0K4OZ7pNsdtumdp7b3X//6FwICAvDxxx/D5XJh9erViImJgclkuuXHW8OHD0dKSgr27duHLVu24Ic//KF7nur9ps/hCwkJgc1mQ2FhIXbv3g2Hw4FTp04hNzfX3cZkMmH58uXIy8tDTk4OHA4HWltbUVlZicuXL3drPVVVVVi1ahXKysrQ3NyMkpISVFRUYOrUqf3Sf1+1tbWhrq4OLS0tOHXqFJ5//nlERkZi2bJlAIAxY8bgiy++wL59++ByuVBbW4uKiooOfYwYMQJVVVUoLy/H9evXvTqsnt5el8uFK1eu4P3330dAQAAiIyMBAH/5y1/w5Zdf4rPPPnN/1PFVzzzzDJqamnDo0KEOX6BQvt/04NRol65fvy4rVqyQkSNHyrBhwyQxMVEyMzMFgISHh8vJkyelqalJ0tPTJTIyUnx9fSUkJERsNpucPn1aduzYIRaLRQDI2LFj5fz585KbmytWq1UASFRUlBw5ckQSEhJk+PDh4uPjI6NHj5aMjAxpaWkREblt/92xfft2CQsLEwBisVhk7ty53arr7NmzsnLlSvHz85N77rlHfH19xWq1yve//305f/68u/9r167Jo48+KiaTSaKjo+XHP/6xrF27VgDImDFj5OLFi/Lvf/9boqKixGw2S2JiolRXV3f7OUAPPmr44IMPJC4uTgwGgwCQsLAw2bhxo/Lt/dWvfiWxsbEC4LaPd955R0RE0tPTZcSIERIcHCwLFiyQN998UwBIbGys+yOPdl//+tflpz/9aaexuN1+s3nzZjGbzQJAIiIi5Pe//323n492t/uooV/CN9StXLlSRowYobSGnoSvr7xhe3vq8ccflwsXLnh8vQP6OR/d1H56e6jw9u3930PYU6dOwWQyITo6WmFFnQ368JWVlXU4jdzVIzU1VXWp1I/S09Px2Wef4ezZs1i+fDl+9rOfqS6pk0EfvvHjx3c6jXyrx9tvv92r/tetW4c9e/agvr4e0dHRg/7ehnrZXovFgvHjx2PmzJnYsGEDJkyYoLqkTjSRjj9ia7+fmAyR37YNFpqmwW638/58XuY2eSoY9K98RN6K4SNShOEjUoThI1KE4SNShOEjUoThI1KE4SNShOEjUoThI1KE4SNShOEjUoThI1Kky7sULViwwJN1UD/Izs5GQUGB6jLof7RfWvNWOv2kqLi4GNu2bRvwoqhvamtr8emnn+KRRx5RXQp1wy3+KBZ0Ch/pA393qXv8PR+RKgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiXd6TnbxHZWUlnnrqKbS2trqnXb16Fb6+vkhKSurQdty4cfj1r3/t4QqpNxg+HQgPD0d5eTkuXLjQaV5RUVGH/0+fPt1TZVEf8bBTJ5YuXQo/P787tktNTfVANdQfGD6dWLJkCVwu123bTJgwAXFxcR6qiPqK4dOJMWPGID4+Hpqm3XK+n58fnnrqKQ9XRX3B8OnI0qVL4ePjc8t5LS0tWLhwoYcror5g+HRk0aJFaGtr6zRd0zQ89NBDuPfeez1fFPUaw6cjo0ePRkJCAgyGjk+bj48Pli5dqqgq6i2GT2eefPLJTtNEBDabTUE11BcMn84sWLCgwyufj48PZs6cidDQUIVVUW8wfDozfPhwfOc733GfeBERpKWlKa6KeoPh06G0tDT3iRdfX1/MnTtXcUXUGwyfDs2dOxdGo9H9b6vVqrgi6g3dfrczPz9fdQlKTZ48Gf/85z8RHR09pMciIiICDz/8sOoyekUTEVFdRG909U0PGlqSk5NRUFCguozeKND1YafdboeIDKmH3W4HADQ3N+Pll19WXo/KR3JysuI9sG90Hb6hzM/PDxs2bFBdBvUBw6djZrNZdQnUBwwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIgwfkSIMH5EiDB+RIkM2fCtWrEBgYCA0TcOJEydUlzNg9u7di5iYGGia1uHh7++P0NBQJCUlISsrC3V1dapLHXKGbPh27dqFnTt3qi5jwNlsNly4cAGxsbEICgqCiKCtrQ01NTXIz89HdHQ00tPTERcXh48++kh1uUPKkA3fUKZpGoKDg5GUlIQ9e/YgPz8fV65cwZw5c1BfX6+6vCFjSIePl6K4KTk5GcuWLUNNTQ3eeust1eUMGUMmfCKCrKwsjBs3DkajEUFBQVi7dm2HNq2trcjMzERkZCTMZjPi4+Pdl23IyclBQEAALBYL9u/fj9mzZ8NqtSI8PBx5eXnuPoqKijBlyhRYLBZYrVZMmjQJDofjjv2rtmzZMgDAu+++C2Boj4XHiE4BELvd3u32GRkZommabN26Verq6sTpdMqOHTsEgJSUlIiIyJo1a8RoNEphYaHU1dXJunXrxGAwyPHjx919AJCjR49KfX291NTUyPTp0yUgIECam5vlxo0bYrVaZfPmzdLY2CjV1dUyf/58qa2t7Vb/3WG326U3T1tsbKwEBQV1Od/hcAgAiYiI0M1YJCcnS3Jyco/HwkvkD4nwOZ1OsVgsMmvWrA7T8/Ly3OFrbGwUi8UiqampHZYzGo2yevVqEfnvDtfY2Ohu0x7gc+fOySeffCIA5NChQ51q6E7/3TFQ4RMR0TRNgoODdTMWeg/fkDjsPHfuHJxOJ2bMmNFlmzNnzsDpdGLixInuaWazGWFhYSgrK+tyOX9/fwCAy+VCTEwMQkNDkZaWhg0bNqC8vLzP/XtKQ0MDRARWq3XIj4WnDInwVVZWAgBCQkK6bNPQ0AAAWL9+fYfPwyoqKuB0Oru1HrPZjGPHjiExMREbN25ETEwMUlNT0djY2C/9D6SzZ88CAMaPHz/kx8JThkT4TCYTAKCpqanLNu3BzM7O7nR9yOLi4m6vKy4uDgcPHkRVVRXS09Nht9uxZcuWfut/oBw+fBgAMHv27CE/Fp4yJMI3ceJEGAwGFBUVddkmIiICJpOpT992qaqqQmlpKYCbYd60aRMmT56M0tLSful/oFRXVyM7Oxvh4eF4+umnh/RYeNKQCF9ISAhsNhsKCwuxe/duOBwOnDp1Crm5ue42JpMJy5cvR15eHnJycuBwONDa2orKykpcvny5W+upqqrCqlWrUFZWhubmZpSUlKCiogJTp07tl/77SkRw48YNtLW1QURQW1sLu92OadOmwcfHB/v27YPVah0SY+EVPHyGp9+ghx81XL9+XVasWCEjR46UYcOGSWJiomRmZgoACQ8Pl5MnT0pTU5Okp6dLZGSk+Pr6SkhIiNhsNjl9+rTs2LFDLBaLAJCxY8fK+fPnJTc3V6xWqwCQqKgoOXLkiCQkJMjw4cPFx8dHRo8eLRkZGdLS0iIictv+u6unZzsPHDgg8fHxYrFYxN/fXwwGgwBwn9mcMmWKvPrqq3Lt2rUOy+lhLPR+tlPXN0qx2+1YuHCh6lI8Kj8/HykpKdDp09avFixYAAC8UQoR9QzDR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6SIr+oC+mIoXemqXfs25+fnK65EvcrKSoSHh6suo9d0fRkJouTkZN1eRkK3r3w6/ZvRb3gtF/3jez4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFGD4iRRg+IkUYPiJFdHtn2qGktrYWf/zjHztM++ijjwAAubm5HaYPGzYMixcv9lht1Hu6vSf7UNLU1ISQkBA0NDTAx8cHwM3bYosIDIb/Hry4XC4sXboUv/3tb1WVSt1XwMNOHTAajViwYAF8fX3hcrngcrnQ0tKC1tZW9/9dLhcA8FVPRxg+nVi8eDGam5tv2yY4OBgzZszwUEXUVwyfTjz66KMICQnpcr6fnx/S0tLg68u38XrB8OmEwWDA4sWL4e/vf8v5LpcLixYt8nBV1BcMn44sWrSoy0PPu+++Gw8//LCHK6K+YPh05KGHHkJUVFSn6X5+fnjqqaegaZqCqqi3GD6defLJJ+Hn59dhGg859Ynh05klS5a4P1ZoN2bMGMTHxyuqiHqL4dOZ8ePHY8KECe5DTD8/PyxfvlxxVdQbDJ8OLV261P1NF5fLhYULFyquiHqD4dOh1NRUtLa2AgC+8Y1vYMyYMYorot5g+HQoKioKDz74IICbr4KkT173xer8/HykpKSoLoMGGS/bzQGgwGu/i2S321WX4NUcDgdycnLwyiuv3HJ+SkoKnn/++SH/wXtxcTHeeOMN1WXckteGjycR7uxb3/oWxo4de8t5KSkpePjhhzmOgNeGj+/5dKyr4JE+MHxEijB8RIowfESKMHxEijB8RIowfESKMHxEijB8RIowfESKMHxEijB8RIowfESKMHxEigzK8K1YsQKBgYHQNA0nTpxQXU6PtbW1ITs7GwkJCR5Z3969exETEwNN0zo8/P39ERoaiqSkJGRlZaGurs4j9QwVgzJ8u3btws6dO1WX0SufffYZHnnkEbz44otwOp0eWafNZsOFCxcQGxuLoKAgiAja2tpQU1OD/Px8REdHIz09HXFxce77AlLfDcrw6dXJkyfxyiuv4JlnnsHXvvY1pbVomobg4GAkJSVhz549yM/Px5UrVzBnzhzU19crrW2wGLTh0+Ol0x944AHs3bsXS5YsgdFoVF1OB8nJyVi2bBlqamrw1ltvqS5nUBgU4RMRZGVlYdy4cTAajQgKCsLatWs7tGltbUVmZiYiIyNhNpsRHx/vvk5MTk4OAgICYLFYsH//fsyePRtWqxXh4eHIy8tz91FUVIQpU6bAYrHAarVi0qRJcDgcd+x/sFi2bBkA4N133wXAMe0z8TJ2u116WlZGRoZomiZbt26Vuro6cTqdsmPHDgEgJSUlIiKyZs0aMRqNUlhYKHV1dbJu3ToxGAxy/Phxdx8A5OjRo1JfXy81NTUyffp0CQgIkObmZrlx44ZYrVbZvHmzNDY2SnV1tcyfP19qa2u71X9PPfTQQ/LAAw/0alkREQBit9t7tExsbKwEBQV1Od/hcAgAiYiIEBF9jGlv9icPyfe6qno6WE6nUywWi8yaNavD9Ly8PHf4GhsbxWKxSGpqaofljEajrF69WkT+u6M0Nja627QH+Ny5c/LJJ58IADl06FCnGrrTf095Y/hERDRNk+DgYN2MqTeHT/eHnefOnYPT6bzt7ZDPnDkDp9OJiRMnuqeZzWaEhYWhrKysy+Xab0TpcrkQExOD0NBQpKWlYcOGDSgvL+9z/3rT0NAAEYHVauWY9gPdh6+yshIAbnvL5IaGBgDA+vXrO3yOVVFR0e3T+WazGceOHUNiYiI2btyImJgYpKamorGxsV/614OzZ88CuHmzFo5p3+k+fCaTCQDQ1NTUZZv2YGZnZ0NEOjyKi4u7va64uDgcPHgQVVVVSE9Ph91ux5YtW/qtf293+PBhAMDs2bM5pv1A9+GbOHEiDAYDioqKumwTEREBk8nUp2+7VFVVobS0FMDNMG/atAmTJ09GaWlpv/Tv7aqrq5GdnY3w8HA8/fTTHNN+oPvwhYSEwGazobCwELt374bD4cCpU6eQm5vrbmMymbB8+XLk5eUhJycHDocDra2tqKysxOXLl7u1nqqqKqxatQplZWVobm5GSUkJKioqMHXq1H7p31uICG7cuIG2tjaICGpra2G32zFt2jT4+Phg3759sFqtHNP+4OEzPHfUm7NT169flxUrVsjIkSNl2LBhkpiYKJmZmQJAwsPD5eTJk9LU1CTp6ekSGRkpvr6+EhISIjabTU6fPi07duwQi8UiAGTs2LFy/vx5yc3NFavVKgAkKipKjhw5IgkJCTJ8+HDx8fGR0aNHS0ZGhrS0tIiI3Lb/7iouLpZp06bJ3XffLQAEgISFhUlCQoIUFRX1aEzQg7OdBw4ckPj4eLFYLOLv7y8Gg0EAuM9sTpkyRV599VW5du1ah+X0MKbefLbTa+9S5GVl6Y6mabDb7UP+Xg1evD8V6P6wk0ivGL4BVlZW1umnOrd6pKamqi6VPMxrbxE2WIwfP94bD3nIC/CVj0gRho9IEYaPSBGGj0gRho9IEYaPSBGGj0gRho9IEYaPSBGGj0gRho9IEYaPSBGGj0gRho9IEa/9SZEe77XgbVJSUpCSkqK6DOqC14UvISFhcF2Pf4AUFxfjjTfe4FjpmNddw4W6x4uvTULdw2u4EKnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEpwvARKcLwESnC8BEp4nV3pqXOXC4Xbty40WFaQ0MDAKCurq7DdE3TEBwc7LHaqPcYPh24du0awsPD0dra2mneiBEjOvw/KSkJf/3rXz1VGvUBDzt1ICwsDI888ggMhts/XZqmYdGiRR6qivqK4dOJJ598Epqm3baNwWCAzWbzUEXUVwyfTthsNvj4+HQ538fHB4899hhGjhzpwaqoLxg+nbBarXjsscfg63vrt+kigrS0NA9XRX3B8OlIWlraLU+6AIC/vz++973vebgi6guGT0eeeOIJWCyWTtN9fX0xb948DBs2TEFV1FsMn46YTCbMnz8ffn5+Haa3tLRgyZIliqqi3mL4dGbx4sVwuVwdplmtVsyaNUtRRdRbDJ/OzJw5s8MH635+fkhNTYW/v7/Cqqg3GD6d8fX1RWpqqvvQ0+VyYfHixYqrot5g+HRo0aJF7kPPUaNGYfr06Yorot5g+HRo2rRpGD16NICb33y509fOyDt53Reri4uLsW3bNtVleL3AwEAAQElJCRYsWKC4Gu9XUFCguoROvO5P5qVLl1BYWKi6DK8XGRmJwMBADB8+/JbzCwsLUVlZ6eGqvE9lZaXX7k9e98rXzhv/Unmb/Px8LFy48JbzNE3DCy+80OX8oSI/Px8pKSmqy7glr3vlo+4b6sHSO4aPSBGGj0gRho9IEYaPSBGGj0gRho9IEYaPSBGGj0gRho9IEYaPSBGGj0gRho9IEYaPSJFBGb4VK1YgMDAQmqbhxIkTqsvptldffRUTJkyA1WqF0WjEmDFj8PLLL3e6PVh/27t3L2JiYqBpWoeHv78/QkNDkZSUhKysrE63I6O+GZTh27VrF3bu3Km6jB47duwYnn32WZSXl+Pq1av4xS9+gTfeeGPAf6lus9lw4cIFxMbGIigoCCKCtrY21NTUID8/H9HR0UhPT0dcXBw++uijAa1lKBmU4dOrYcOGYeXKlRgxYgQCAwOxcOFCzJs3D4cPH8alS5c8Wkv7TTaTkpKwZ88e5Ofn48qVK5gzZw7q6+s9WstgNWjDd6fbaXmjQ4cOdboT0V133QUAcDqdKkpyS05OxrJly1BTU4O33npLaS2DxaAIn4ggKysL48aNg9FoRFBQENauXduhTWtrKzIzMxEZGQmz2Yz4+HjY7XYAQE5ODgICAmCxWLB//37Mnj0bVqsV4eHhyMvLc/dRVFSEKVOmwGKxwGq1YtKkSXA4HHfsvy8+//xzmM1mREdH97mvvlq2bBkA4N133wWg3zH1GuJl7Ha79LSsjIwM0TRNtm7dKnV1deJ0OmXHjh0CQEpKSkREZM2aNWI0GqWwsFDq6upk3bp1YjAY5Pjx4+4+AMjRo0elvr5eampqZPr06RIQECDNzc1y48YNsVqtsnnzZmlsbJTq6mqZP3++1NbWdqv/3mhoaJDAwEB57rnnerwsALHb7T1aJjY2VoKCgrqc73A4BIBERESIiD7GtDf7k4fke11VPR0sp9MpFotFZs2a1WF6Xl6eO3yNjY1isVgkNTW1w3JGo1FWr14tIv/dURobG91t2gN87tw5+eSTTwSAHDp0qFMN3em/NzIyMuS+++4Th8PR42UHInwiIpqmSXBwsG7G1JvDp/vDznPnzsHpdGLGjBldtjlz5gycTicmTpzonmY2mxEWFoaysrIul2u//4HL5UJMTAxCQ0ORlpaGDRs2oLy8vM/9384777yD/Px8vPfee+5rdKrW0NAAEYHVatXlmHob3Yev/dqUISEhXbZpaGgAAKxfv77D51gVFRXdPpFhNptx7NgxJCYmYuPGjYiJiUFqaioaGxv7pf//9fbbb+O1117D+++/j3vvvbfHyw+Us2fPAgDGjx+vuzH1RroPn8lkAgA0NTV12aY9mNnZ2RCRDo/i4uJurysuLg4HDx5EVVUV0tPTYbfbsWXLln7rHwC2b9+OP/zhDzh27Jj7kvDe4vDhwwCA2bNn62pMvZXuwzdx4kQYDAYUFRV12SYiIgImk6lP33apqqpCaWkpgJth3rRpEyZPnozS0tJ+6V9EkLDaqhsAAAIvSURBVJ6ejo8//hj79u3zurvMVldXIzs7G+Hh4Xj66ad1MabeTvfhCwkJgc1mQ2FhIXbv3g2Hw4FTp04hNzfX3cZkMmH58uXIy8tDTk4OHA4HWltbUVlZicuXL3drPVVVVVi1ahXKysrQ3NyMkpISVFRUYOrUqf3Sf2lpKV5//XXs3LkTfn5+nb7qtWXLll6NT0+JCG7cuIG2tjaICGpra2G32zFt2jT4+Phg3759sFqtuhhTr+fZEzx31puzU9evX5cVK1bIyJEjZdiwYZKYmCiZmZkCQMLDw+XkyZPS1NQk6enpEhkZKb6+vhISEiI2m01Onz4tO3bsEIvFIgBk7Nixcv78ecnNzRWr1SoAJCoqSo4cOSIJCQkyfPhw8fHxkdGjR0tGRoa0tLSIiNy2/+74+OOPBUCXj6ysrB6NCXpwtvPAgQMSHx8vFotF/P39xWAwCAD3mc0pU6bIq6++KteuXeuwnLePqYh3n+3UREQ8H/mutV9b38vK0h1N02C324f8JeW9eH8q0P1hJ5FeMXwDrKysrNP7t1s9UlNTVZdKHua1twgbLMaPH++NhzzkBfjKR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6QIw0ekCMNHpAjDR6QIw0ekiNf+pGig78wzFGRnZ6OgoEB1GUq1X1rSG3ndZSSKi4uxbds21WXQIOOFf4QKvC58REMEr+FCpArDR6QIw0ekCMNHpMj/AwKyCDvhY122AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVvUxpAkOQuz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "f31e629c-ca77-455a-b939-14634cb3fabe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history =network.fit(train_images, train_labels, validation_split=0.33,epochs=5, batch_size=512)\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.2678 - accuracy: 0.9282 - val_loss: 0.2633 - val_accuracy: 0.9298\n",
            "Epoch 2/5\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.2675 - accuracy: 0.9283 - val_loss: 0.2632 - val_accuracy: 0.9297\n",
            "Epoch 3/5\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.2673 - accuracy: 0.9283 - val_loss: 0.2631 - val_accuracy: 0.9296\n",
            "Epoch 4/5\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.2670 - accuracy: 0.9283 - val_loss: 0.2630 - val_accuracy: 0.9294\n",
            "Epoch 5/5\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.2667 - accuracy: 0.9284 - val_loss: 0.2628 - val_accuracy: 0.9293\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}